{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSY340 Project - Trajectory Estimation LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in group number and member names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME1 = \"Bingcheng Chen\" \n",
    "NAME2 = \"Arvin Rokni\"\n",
    "GROUP = \"Project groups 64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import dataloader\n",
    "import model_LSTM\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model save location\n",
    "save_location = \"./models\"\n",
    "# defining dataset locations\n",
    "dataset_folder = \"./trajectory-prediction-transformers/datasets\"\n",
    "dataset_name = \"raw\"\n",
    "# setting validation size. if val_size = 0, split percentage is 80-20\n",
    "val_size = 0\n",
    "# length of sequence given to encoder\n",
    "gt = 8\n",
    "# length of sequence given to decoder\n",
    "horizon = 12\n",
    "\n",
    "\n",
    "train_dataset, _ = dataloader.create_dataset(dataset_folder, dataset_name, val_size, \\\n",
    "    gt, horizon, delim=\"\\t\", train=True)\n",
    "val_dataset, _ = dataloader.create_dataset(dataset_folder, dataset_name, val_size, \\\n",
    "    gt, horizon, delim=\"\\t\", train=False)\n",
    "# test_dataset, _ = dataloader.create_dataset(dataset_folder, dataset_name, val_size, \\\n",
    "#     gt, horizon, delim=\"\\t\", train=False, eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': tensor([[ 4.9693e+00,  8.3395e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 5.1330e+00,  8.3350e+00,  1.6374e-01, -4.5338e-03],\n",
       "         [ 5.2968e+00,  8.3307e+00,  1.6374e-01, -4.2963e-03],\n",
       "         [ 5.3915e+00,  8.3490e+00,  9.4709e-02,  1.8377e-02],\n",
       "         [ 5.4565e+00,  8.3774e+00,  6.5034e-02,  2.8400e-02],\n",
       "         [ 5.5218e+00,  8.4058e+00,  6.5244e-02,  2.8400e-02],\n",
       "         [ 5.5868e+00,  8.4342e+00,  6.5033e-02,  2.8400e-02],\n",
       "         [ 5.5988e+00,  8.4497e+00,  1.1997e-02,  1.5512e-02]]),\n",
       " 'trg': tensor([[ 5.5575e+00,  8.4521e+00, -4.1251e-02,  2.3870e-03],\n",
       "         [ 5.5163e+00,  8.4548e+00, -4.1251e-02,  2.6255e-03],\n",
       "         [ 5.4750e+00,  8.4571e+00, -4.1251e-02,  2.3861e-03],\n",
       "         [ 5.4340e+00,  8.4595e+00, -4.1041e-02,  2.3870e-03],\n",
       "         [ 5.3927e+00,  8.4622e+00, -4.1251e-02,  2.6245e-03],\n",
       "         [ 5.3515e+00,  8.4645e+00, -4.1251e-02,  2.3870e-03],\n",
       "         [ 5.3102e+00,  8.4669e+00, -4.1251e-02,  2.3861e-03],\n",
       "         [ 5.2690e+00,  8.4696e+00, -4.1251e-02,  2.6255e-03],\n",
       "         [ 5.2277e+00,  8.4719e+00, -4.1251e-02,  2.3870e-03],\n",
       "         [ 5.0924e+00,  8.4832e+00, -1.3533e-01,  1.1217e-02],\n",
       "         [ 4.9337e+00,  8.4968e+00, -1.5869e-01,  1.3603e-02],\n",
       "         [ 4.7748e+00,  8.5101e+00, -1.5890e-01,  1.3365e-02]]),\n",
       " 'frames': array([6130., 6140., 6150., 6160., 6170., 6180., 6190., 6200., 6210.,\n",
       "        6220., 6230., 6240., 6250., 6260., 6270., 6280., 6290., 6300.,\n",
       "        6310., 6320.]),\n",
       " 'seq_start': array([[4.9692917, 8.339489 ]], dtype=float32),\n",
       " 'dataset': 0,\n",
       " 'peds': 95.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[10]['src'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining batch size\n",
    "batch_size = 64\n",
    "\n",
    "# creating torch dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the mean and standard deviation of velocities of the entire dataset\n",
    "mean = torch.cat((train_dataset[:]['src'][:, 1:, 2:4],\n",
    "                    train_dataset[:]['trg'][:, :, 2:4]), 1).mean((0, 1))\n",
    "std = torch.cat((train_dataset[:]['src'][:, 1:, 2:4],\n",
    "                train_dataset[:]['trg'][:, :, 2:4]), 1).std((0, 1))\n",
    "means = []\n",
    "stds = []\n",
    "for i in np.unique(train_dataset[:]['dataset']):\n",
    "    ind = train_dataset[:]['dataset'] == i\n",
    "    means.append(torch.cat(\n",
    "        (train_dataset[:]['src'][ind, 1:, 2:4], train_dataset[:]['trg'][ind, :, 2:4]), 1).mean((0, 1)))\n",
    "    stds.append(\n",
    "        torch.cat((train_dataset[:]['src'][ind, 1:, 2:4], train_dataset[:]['trg'][ind, :, 2:4]), 1).std((0, 1)))\n",
    "mean = torch.stack(means).mean(0)\n",
    "std = torch.stack(stds).mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "LSTM_model = model_LSTM.LSTM(input_size=2, hidden_size=128, num_layers=2, output_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (LSTM_first_layer): ModuleList(\n",
       "    (0): LSTMCell(\n",
       "      (W_hh): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (W_xh): Linear(in_features=2, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): LSTMCell(\n",
       "      (W_hh): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (W_xh): Linear(in_features=128, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (LSTM_whole): ModuleList(\n",
       "    (0): LSTMCell(\n",
       "      (W_hh): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (W_xh): Linear(in_features=2, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): LSTMCell(\n",
       "      (W_hh): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (W_xh): Linear(in_features=128, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 70\n",
    "\n",
    "# creating optimizer\n",
    "optimizer = torch.optim.SGD(tf_model.parameters(\n",
    "), lr=1e-4, momentum=0.9, weight_decay=1e-3, nesterov=True)\n",
    "# optimizer = torch.optim.Adam(tf_model.parameters(), lr=1e-4)\n",
    "\n",
    "train_loss, learning_rates = utils.learning_rate_finder(\n",
    "    tf_model, optimizer, train_loader, iterations, device, mean, std)\n",
    "eta_star = learning_rates[np.argmin(np.array(train_loss))]\n",
    "eta_max = eta_star/10\n",
    "print(\"Value of eta max is: {:.4f}\".format(eta_max))\n",
    "\n",
    "# plotting results\n",
    "# plt.figure()\n",
    "# plt.plot(learning_rates, train_loss)\n",
    "# plt.xlabel(\"Learning rates\")\n",
    "# plt.ylabel(\"Training loss\")\n",
    "# plt.xscale('log')\n",
    "# plt.title(\"Learning Rate Finder Algorithm\")\n",
    "# plt.show()\n",
    "\n",
    "# number of epochs\n",
    "epochs = 1\n",
    "\n",
    "# metric variables\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "val_mad = []\n",
    "val_fad = []\n",
    "\n",
    "# finding the total number of weight updates for the network\n",
    "T = epochs * len(train_loader)\n",
    "# initializing variable to track the number of weight updates\n",
    "weight_update = 0\n",
    "# initializing variable to store the changing learning rate\n",
    "learning_rate = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # TRAINING MODE\n",
    "    tf_model.train()\n",
    "\n",
    "    # training batch variables\n",
    "    train_batch_loss = 0\n",
    "\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        # changing the learning rate based on cosine scheduler\n",
    "        lr = utils.cosine_scheduler(weight_update, eta_max, T)\n",
    "        for param in optimizer.param_groups:\n",
    "            learning_rate.append(lr)\n",
    "            param['lr'] = lr\n",
    "        weight_update += 1\n",
    "\n",
    "        # getting encoder input data\n",
    "        # (64, 7, 512)\n",
    "        enc_input = (data['src'][:, 1:, 2:4].to(\n",
    "            device)-mean.to(device))/std.to(device)\n",
    "\n",
    "        # getting decoder input data\n",
    "        target = (data['trg'][:, :-1, 2:4].to(device) -\n",
    "                    mean.to(device))/std.to(device)\n",
    "        target_append = torch.zeros(\n",
    "            (target.shape[0], target.shape[1], 1)).to(device)\n",
    "        target = torch.cat((target, target_append), -1)\n",
    "        start_of_seq = torch.Tensor([0, 0, 1]).unsqueeze(\n",
    "            0).unsqueeze(1).repeat(target.shape[0], 1, 1).to(device)\n",
    "        (64, 12, 512)\n",
    "        dec_input = torch.cat((start_of_seq, target), 1)\n",
    "\n",
    "        # getting masks for decoder\n",
    "        dec_source_mask = torch.ones(\n",
    "            (enc_input.shape[0], 1, enc_input.shape[1])).to(device)\n",
    "        dec_target_mask = utils.subsequent_mask(\n",
    "            dec_input.shape[1]).repeat(dec_input.shape[0], 1, 1).to(device)\n",
    "\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        # predictions = tf_model.forward(enc_input, dec_input, dec_source_mask, dec_target_mask)\n",
    "        predictions = tf_model.forward(enc_input, dec_input)\n",
    "\n",
    "        # calculating loss using pairwise distance of all predictions\n",
    "        loss = F.pairwise_distance(predictions[:, :, 0:2].contiguous().view(-1, 2),\n",
    "                                    ((data['trg'][:, :, 2:4].to(device)-mean.to(device))/std.to(device)).\n",
    "                                    contiguous().view(-1, 2).to(device)).mean() + \\\n",
    "            torch.mean(torch.abs(predictions[:, :, 2]))\n",
    "        train_batch_loss += loss.item()\n",
    "\n",
    "        # updating weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    training_loss.append(train_batch_loss/len(train_loader))\n",
    "    print(\"Epoch {}/{}....Training loss = {:.4f}\".format(epoch +\n",
    "            1, epochs, training_loss[-1]))\n",
    "\n",
    "    # validation loop\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            # EVALUATION MODE\n",
    "            tf_model.eval()\n",
    "\n",
    "            # validation variables\n",
    "            batch_val_loss = 0\n",
    "            gt = []\n",
    "            pr = []\n",
    "\n",
    "            for id_b, data in enumerate(val_loader):\n",
    "                # storing groung truth\n",
    "                gt.append(data['trg'][:, :, 0:2])\n",
    "\n",
    "                # input to encoder input\n",
    "                val_input = (data['src'][:, 1:, 2:4].to(\n",
    "                    device)-mean.to(device))/std.to(device)\n",
    "\n",
    "                # input to decoder\n",
    "                start_of_seq = torch.Tensor([0, 0, 1]).unsqueeze(0).unsqueeze(\n",
    "                    1).repeat(val_input.shape[0], 1, 1).to(device)\n",
    "                dec_inp = start_of_seq\n",
    "                # decoder masks\n",
    "                dec_source_mask = torch.ones(\n",
    "                    (val_input.shape[0], 1, val_input.shape[1])).to(device)\n",
    "                dec_target_mask = utils.subsequent_mask(\n",
    "                    dec_inp.shape[1]).repeat(dec_inp.shape[0], 1, 1).to(device)\n",
    "\n",
    "                # prediction till horizon lenght\n",
    "                for i in range(horizon):\n",
    "                    # getting model prediction\n",
    "                    # model_output = tf_model.forward(val_input, dec_inp, dec_source_mask, dec_target_mask)\n",
    "                    model_output = tf_model.forward(val_input, dec_inp)\n",
    "\n",
    "                    # appending the predicition to decoder input for next cycle\n",
    "                    dec_inp = torch.cat(\n",
    "                        (dec_inp, model_output[:, -1:, :]), 1)\n",
    "\n",
    "                # calculating loss using pairwise distance of all predictions\n",
    "                val_loss = F.pairwise_distance(dec_inp[:, 1:, 0:2].contiguous().view(-1, 2),\n",
    "                                                ((data['trg'][:, :, 2:4].to(device)-mean.to(device))/std.to(device)).\n",
    "                                                contiguous().view(-1, 2).to(device)).mean() + \\\n",
    "                    torch.mean(torch.abs(dec_inp[:, 1:, 2]))\n",
    "                batch_val_loss += val_loss.item()\n",
    "\n",
    "                # calculating the position for each time step of prediction based on velocity\n",
    "                preds_tr_b = (dec_inp[:, 1:, 0:2]*std.to(device) + mean.to(device)).cpu().numpy().cumsum(1) + \\\n",
    "                    data['src'][:, -1:, 0:2].cpu().numpy()\n",
    "\n",
    "                pr.append(preds_tr_b)\n",
    "            validation_loss.append(batch_val_loss/len(val_loader))\n",
    "\n",
    "            # calculating mad and fad evaluation metrics\n",
    "            gt = np.concatenate(gt, 0)\n",
    "            pr = np.concatenate(pr, 0)\n",
    "            mad, fad, _ = dataloader.distance_metrics(gt, pr)\n",
    "            val_mad.append(mad)\n",
    "            val_fad.append(fad)\n",
    "\n",
    "            print(\"Epoch {}/{}....Validation mad = {:.4f}, Validation fad = {:.4f}\".format(\n",
    "                epoch+1, epochs, mad, fad))\n",
    "\n",
    "    # Saving model, loss and error log files\n",
    "    torch.save({\n",
    "        'model_state_dict': tf_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'training_loss': training_loss,\n",
    "        'validation_loss': validation_loss,\n",
    "        'val_mad': val_mad,\n",
    "        'val_fad': val_fad,\n",
    "        'learning_rate': learning_rate\n",
    "    }, os.path.join(save_location, 'epoch{}.pth'.format(epoch+1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "loaded_file = torch.load(os.path.join(\n",
    "    save_location, 'epoch10.pth'), map_location=torch.device(device))\n",
    "\n",
    "# creating model and loading weights\n",
    "# encoder_ip_size = 2\n",
    "# decoder_ip_size = 3\n",
    "# model_op_size = 3\n",
    "# emb_size = 512\n",
    "# num_heads = 8\n",
    "# ff_hidden_size = 2048\n",
    "# n = 6\n",
    "# dropout = 0.1\n",
    "\n",
    "# model_loaded = model.TFModel(encoder_ip_size, decoder_ip_size, model_op_size, emb_size,\n",
    "#                              num_heads, ff_hidden_size, n, dropout=0.1)\n",
    "\n",
    "model_loaded = model_cbc.Transformer(encoder_input_size=2, decoder_input_size=3,\n",
    "                                embedding_size=512, num_heads=8, num_layers=6, feedforward_size=2048)\n",
    "\n",
    "\n",
    "model_loaded = model_loaded.to(device)\n",
    "model_loaded.load_state_dict(loaded_file['model_state_dict'])\n",
    "\n",
    "# loading training metric variables\n",
    "training_loss = loaded_file['training_loss']\n",
    "validation_loss = loaded_file['validation_loss']\n",
    "val_mad = loaded_file['val_mad']\n",
    "val_fad = loaded_file['val_fad']\n",
    "learning_rate = loaded_file['learning_rate']\n",
    "\n",
    "# plotting training loss\n",
    "plt.figure()\n",
    "plt.plot(training_loss)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.title(\"Training loss VS Number of Epochs\")\n",
    "\n",
    "# plotting validation loss\n",
    "plt.figure()\n",
    "plt.plot(validation_loss)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Validation loss\")\n",
    "plt.title(\"Validation loss VS Number of Epochs\")\n",
    "\n",
    "# plotting training and validation loss together\n",
    "plt.figure()\n",
    "plt.plot(loaded_file['training_loss'], label=\"training loss\")\n",
    "plt.plot(np.arange(1, 10, 5),\n",
    "            loaded_file['validation_loss'], label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Training v/s Validation loss\")\n",
    "plt.savefig(\"loss.png\")\n",
    "\n",
    "# plotting learning rate for model\n",
    "plt.figure()\n",
    "plt.plot(learning_rate)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"learning_rate\")\n",
    "plt.title(\"Learning_rate VS Number of Epochs\")\n",
    "\n",
    "# plotting MAD\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, 10, 5),\n",
    "            loaded_file['val_mad'], label=\"validation MAD\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MAD (m)\")\n",
    "plt.title(\"Mean Average Displacement\")\n",
    "plt.savefig(\"mad.png\")\n",
    "\n",
    "# plotting FAD\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, 10, 5),\n",
    "            loaded_file['val_fad'], label=\"validation FAD\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"FAD (m)\")\n",
    "plt.title(\"Final Average Displacement\")\n",
    "plt.savefig(\"fad.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the validation loop to generate prediction trajectories on validation data\n",
    "validation_loss = []\n",
    "val_mad = []\n",
    "val_fad = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # EVALUATION MODE\n",
    "    model_loaded.eval()\n",
    "\n",
    "    # validation variables\n",
    "    batch_val_loss = 0\n",
    "    gt = []\n",
    "    pr = []\n",
    "    obs = []\n",
    "\n",
    "    for id_b, data in enumerate(val_loader):\n",
    "        # storing groung truth\n",
    "        gt.append(data['trg'][:, :, 0:2])\n",
    "        obs.append(data['src'][:, :, 0:2])\n",
    "        # input to encoder input\n",
    "        val_input = (data['src'][:, 1:, 2:4].to(\n",
    "            device)-mean.to(device))/std.to(device)\n",
    "\n",
    "        # input to decoder\n",
    "        start_of_seq = torch.Tensor([0, 0, 1]).unsqueeze(0).unsqueeze(\n",
    "            1).repeat(val_input.shape[0], 1, 1).to(device)\n",
    "        dec_inp = start_of_seq\n",
    "        # decoder masks\n",
    "        dec_source_mask = torch.ones(\n",
    "            (val_input.shape[0], 1, val_input.shape[1])).to(device)\n",
    "        dec_target_mask = utils.subsequent_mask(\n",
    "            dec_inp.shape[1]).repeat(dec_inp.shape[0], 1, 1).to(device)\n",
    "\n",
    "        # prediction till horizon lenght\n",
    "        for i in range(horizon):\n",
    "            # getting model prediction\n",
    "            # model_output = model_loaded.forward(\n",
    "            #     val_input, dec_inp, dec_source_mask, dec_target_mask)\n",
    "\n",
    "            model_output = model_loaded.forward(val_input, dec_inp)\n",
    "\n",
    "            # appending the predicition to decoder input for next cycle\n",
    "            dec_inp = torch.cat((dec_inp, model_output[:, -1:, :]), 1)\n",
    "\n",
    "        # calculating loss using pairwise distance of all predictions\n",
    "        val_loss = F.pairwise_distance(dec_inp[:, 1:, 0:2].contiguous().view(-1, 2),\n",
    "                                        ((data['trg'][:, :, 2:4].to(device)-mean.to(device))/std.to(device)).\n",
    "                                        contiguous().view(-1, 2).to(device)).mean() + \\\n",
    "            torch.mean(torch.abs(dec_inp[:, 1:, 2]))\n",
    "        batch_val_loss += val_loss.item()\n",
    "\n",
    "        # calculating the position for each time step of prediction based on velocity\n",
    "        preds_tr_b = (dec_inp[:, 1:, 0:2]*std.to(device) + mean.to(device)).cpu().numpy().cumsum(1) + \\\n",
    "            data['src'][:, -1:, 0:2].cpu().numpy()\n",
    "\n",
    "        pr.append(preds_tr_b)\n",
    "        validation_loss.append(batch_val_loss/len(val_loader))\n",
    "\n",
    "    # calculating mad and fad evaluation metrics\n",
    "    gt = np.concatenate(gt, 0)\n",
    "    pr = np.concatenate(pr, 0)\n",
    "    obs = np.concatenate(obs, 0)\n",
    "    mad, fad, _ = dataloader.distance_metrics(gt, pr)\n",
    "    val_mad.append(mad)\n",
    "    val_fad.append(fad)\n",
    "\n",
    "# plotting the predicted and ground truth trajectories\n",
    "idx = np.random.randint(0, gt.shape[0])\n",
    "plt.figure()\n",
    "plt.scatter(gt[idx, :, 0], gt[idx, :, 1],\n",
    "            color='green', label=\"Ground truth\")\n",
    "plt.scatter(pr[idx, :, 0], pr[idx, :, 1],\n",
    "            color='orange', label=\"Predictions\")\n",
    "plt.scatter(obs[idx, :, 0], obs[idx, :, 1],\n",
    "            color='b', label=\"Observations\")\n",
    "plt.legend()\n",
    "plt.xlim(-8, 18)\n",
    "plt.ylim(-11, 15)\n",
    "plt.title(\"Trajectory Visualization in camera frame\")\n",
    "plt.xlabel(\"X (m)\")\n",
    "plt.ylabel(\"Y (m)\")\n",
    "plt.savefig(\"traj_{}\".format(idx))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the predicted and ground truth trajectories\n",
    "idx = np.random.randint(0, gt.shape[0])\n",
    "plt.figure()\n",
    "plt.scatter(gt[idx, :, 0], gt[idx, :, 1],\n",
    "            color='green', label=\"Ground truth\")\n",
    "plt.scatter(pr[idx, :, 0], pr[idx, :, 1],\n",
    "            color='orange', label=\"Predictions\")\n",
    "plt.scatter(obs[idx, :, 0], obs[idx, :, 1],\n",
    "            color='b', label=\"Observations\")\n",
    "plt.legend()\n",
    "plt.xlim(-8, 18)\n",
    "plt.ylim(-11, 15)\n",
    "plt.title(\"Trajectory Visualization in camera frame\")\n",
    "plt.xlabel(\"X (m)\")\n",
    "plt.ylabel(\"Y (m)\")\n",
    "plt.savefig(\"traj_{}\".format(idx))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
