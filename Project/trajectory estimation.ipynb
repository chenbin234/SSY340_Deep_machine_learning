{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSY340 Project - Trajectory Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in group number and member names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME1 = \"Bingcheng Chen\" \n",
    "NAME2 = \"Arvin Rokni\"\n",
    "GROUP = \"Project groups 64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model.Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loss_fn, train_loader, val_loader, device, print_every):\n",
    "    # Train:\n",
    "    model.train()\n",
    "    \n",
    "    train_loss_batches = []\n",
    "\n",
    "    num_batches = len(train_loader)\n",
    "\n",
    "    for batch_index, data in enumerate(train_loader):\n",
    "\n",
    "        # prepare the input\n",
    "        encoder_input = 0\n",
    "        decoder_input = 0\n",
    "        decoder_source_mask = 0\n",
    "        decoder_target_mask = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = transformer_model.forward(encoder_input, decoder_input) # add mask ?\n",
    "\n",
    "        loss = F.pairwise_distance()\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_batches.append(loss.item())\n",
    "\n",
    "        # If you want to print your progress more often than every epoch you can\n",
    "        # set `print_every` to the number of batches you want between every status update.\n",
    "        # Note that the print out will trigger a full validation on the full val. set => slows down training\n",
    "        if print_every is not None and batch_index % print_every == 0:\n",
    "            val_loss = validate(model, loss_fn, val_loader, device)\n",
    "            model.train()\n",
    "            print(f\"\\tBatch {batch_index}/{num_batches}: \"\n",
    "                  f\"\\tTrain loss: {sum(train_loss_batches[-print_every:])/print_every:.3f}, \"\n",
    "                  f\"\\tVal. loss: {val_loss:.3f}, \"\n",
    "\n",
    "    return model, train_loss_batches\n",
    "\n",
    "def validate(model, loss_fn, val_loader, device):\n",
    "                    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        batch_val_loss=0\n",
    "        gt = []\n",
    "        pr = []\n",
    "        model.eval()\n",
    "\n",
    "        for id_b, data in enumerate(val_loader):\n",
    "            # storing groung truth \n",
    "            gt.append(data['trg'][:, :, 0:2])\n",
    "\n",
    "            # input to encoder input\n",
    "            val_input = (data['src'][:,1:,2:4].to(device)-mean.to(device))/std.to(device)\n",
    "\n",
    "            # input to decoder\n",
    "            start_of_seq = torch.Tensor([0, 0, 1]).unsqueeze(0).unsqueeze(1).repeat(val_input.shape[0], 1, 1).to(device)\n",
    "            dec_inp = start_of_seq\n",
    "            # decoder masks\n",
    "            dec_source_mask = torch.ones((val_input.shape[0], 1, val_input.shape[1])).to(device)\n",
    "            dec_target_mask = utils.subsequent_mask(dec_inp.shape[1]).repeat(dec_inp.shape[0], 1, 1).to(device)\n",
    "\n",
    "            # prediction till horizon lenght\n",
    "            for i in range(horizon):\n",
    "                # getting model prediction\n",
    "                model_output = tf_model.forward(val_input, dec_inp, dec_source_mask, dec_target_mask)\n",
    "                # appending the predicition to decoder input for next cycle\n",
    "                dec_inp = torch.cat((dec_inp, model_output[:, -1:, :]), 1)\n",
    "\n",
    "            # calculating loss using pairwise distance of all predictions\n",
    "            val_loss = F.pairwise_distance(dec_inp[:,1:,0:2].contiguous().view(-1, 2),\n",
    "                                    ((data['trg'][:, :, 2:4].to(device)-mean.to(device))/std.to(device)).\\\n",
    "                                        contiguous().view(-1, 2).to(device)).mean() + \\\n",
    "                                        torch.mean(torch.abs(dec_inp[:,1:,2]))\n",
    "            batch_val_loss += val_loss.item()\n",
    "\n",
    "            # calculating the position for each time step of prediction based on velocity\n",
    "            preds_tr_b = (dec_inp[:, 1:, 0:2]*std.to(device) + mean.to(device)).cpu().numpy().cumsum(1) + \\\n",
    "                data['src'][:,-1:,0:2].cpu().numpy()\n",
    "\n",
    "            pr.append(preds_tr_b)\n",
    "        validation_loss.append(batch_val_loss/len(val_loader))\n",
    "\n",
    "        # calculating mad and fad evaluation metrics\n",
    "        gt = np.concatenate(gt, 0)\n",
    "        pr = np.concatenate(pr, 0)\n",
    "        mad, fad, _ = dataloader.distance_metrics(gt, pr)\n",
    "        val_mad.append(mad)\n",
    "        val_fad.append(fad)\n",
    "\n",
    "        print(\"Epoch {}/{}....Validation mad = {:.4f}, Validation fad = {:.4f}\".format(epoch+1, epochs, mad, fad))\n",
    "\n",
    "def training_loop(model, optimizer, loss_fn, train_loader, val_loader, num_epochs, print_every):\n",
    "    print(\"Starting training\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model, train_loss, train_acc = train_epoch(model,\n",
    "                                                   optimizer,\n",
    "                                                   loss_fn,\n",
    "                                                   train_loader,\n",
    "                                                   val_loader,\n",
    "                                                   device,\n",
    "                                                   print_every)\n",
    "        val_loss, val_acc = validate(model, loss_fn, val_loader, device)\n",
    "        print(f\"Epoch {epoch}/{num_epochs}: \"\n",
    "              f\"Train loss: {sum(train_loss)/len(train_loss):.3f}, \"\n",
    "              f\"Train acc.: {sum(train_acc)/len(train_acc):.3f}, \"\n",
    "              f\"Val. loss: {val_loss:.3f}, \"\n",
    "              f\"Val. acc.: {val_acc:.3f}\")\n",
    "        train_losses.extend(train_loss)\n",
    "        train_accs.extend(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "    return model, train_losses, train_accs, val_losses, val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.pairwise_distance()\n",
    "\n",
    "optimizer = torch.optim.SGD(tf_model.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-3, nesterov=True)\n",
    "num_epochs = 10\n",
    "\n",
    "first_model, first_train_losses, first_train_accs, first_val_losses, first_val_accs = training_loop(model, optimizer, loss_fn, train_dataloader, val_dataloader, num_epochs=num_epochs, print_every=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
